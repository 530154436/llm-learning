[transformerå­¦ä¹ ]
[æå®æ¯…-è‡ªæ³¨æ„åŠ›æœºåˆ¶ Self-attentionï¼ˆä¸Šï¼‰](https://www.bilibili.com/video/BV1Wv411h7kN?spm_id_from=333.788.videopod.episodes&vd_source=436107f586d66ab4fcf756c76eb96c35&p=38)
[æå®æ¯…-Transformerï¼ˆä¸Šï¼‰](https://www.bilibili.com/video/BV1Wv411h7kN/?p=49&share_source=copy_web&vd_source=e46571d631061853c8f9eead71bdb390)
[ææ²-Transformerè®ºæ–‡é€æ®µç²¾è¯»ã€è®ºæ–‡ç²¾è¯»ã€‘](https://www.bilibili.com/video/BV1pu411o7BE/?share_source=copy_web&vd_source=e46571d631061853c8f9eead71bdb390)
[3Blue1Brown-ã€å®˜æ–¹åŒè¯­ã€‘GPTæ˜¯ä»€ä¹ˆï¼Ÿç›´è§‚è§£é‡ŠTransformer | ã€æ·±åº¦å­¦ä¹ ç¬¬5ç« ã€‘](https://www.bilibili.com/video/BV13z421U7cs/?share_source=copy_web&vd_source=e46571d631061853c8f9eead71bdb390)
[3Blue1Brown-ã€å®˜æ–¹åŒè¯­ã€‘ç›´è§‚è§£é‡Šæ³¨æ„åŠ›æœºåˆ¶ï¼ŒTransformerçš„æ ¸å¿ƒ | ã€æ·±åº¦å­¦ä¹ ç¬¬6ç« ã€‘](https://www.bilibili.com/video/BV1TZ421j7Ke/?share_source=copy_web)

â­Transformer è®ºæ–‡ç²¾è¯»
https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/tree/master/PaperNotes

â­ã€Šå¤§è¯­è¨€æ¨¡å‹ï¼šä»ç†è®ºåˆ°å®è·µv2.2025.å¼ å¥‡ã€‹transformerç»„ä»¶å®ç°+æœºå™¨ç¿»è¯‘å®æˆ˜
https://github.com/intro-llm/intro-llm-code/blob/main/chs/ch2-foundations/Transformer

å“ˆä½›NLPå®ç°ï¼š
åšå®¢ï¼šhttps://nlp.seas.harvard.edu/annotated-transformer/#training
ä»£ç ï¼šhttps://github.com/mcxiaoxiao/annotated-transformer-Chinese/blob/main/AnnotatedTransformer%20%E4%B8%AD%E6%96%87.ipynb

PPTå¯ä»¥
ã€Transformer çš„ Pytorch ä»£ç å®ç°è®²è§£-å“”å“©å“”å“©ã€‘ https://b23.tv/pPamgsI
æºç æ˜¯githubä¸Šç°æˆçš„å“¦ï½é“¾æ¥ğŸ”— https://github.com/wmathor/nlp-tutorial/blob/master/5-1.Transformer/Transformer_Torch.py#L122
è§†é¢‘ä¸­ç”¨åˆ°çš„ ppt é“¾æ¥åœ¨è¿™é‡Œå•¦ï¼šé“¾æ¥ğŸ”— https://pan.quark.cn/s/6e55ac9f40d9
https://github.com/zxuu/Self-Attention/blob/main/My_Transformer.py

Transformerå¸¸è§é—®é¢˜ä¸å›ç­”æ€»ç»“
https://zhuanlan.zhihu.com/p/496012402?utm_medium=social&utm_oi=629375409599549440

æ¯”è¾ƒæ¸…æ™°çš„å„æ¨¡å—å®ç°
https://github.com/hyunwoongko/transformer/blob/master/models/blocks/decoder_layer.py

datawhalechina
https://github.com/datawhalechina/fun-transformer/tree/main


[transformerå®æˆ˜-æœºå™¨ç¿»è¯‘]
åšå®¢ï¼šhttps://zhuanlan.zhihu.com/p/347061440
ä»£ç ï¼šhttps://github.com/hemingkx/ChineseNMT/tree/master
ç ”ç©¶ç”Ÿå®éªŒ2ï¼šåŸºäºåºåˆ—æ¨¡å‹çš„è‹±æ–‡åˆ°ä¸­æ–‡ç¿»è¯‘æœºï¼šhttps://www.zybuluo.com/wujiaju/note/1885072

HUuggingfaceï¼šhttps://huggingface.co/learn/llm-course/zh-CN/chapter7/4?fw=pt
PyTorchå®˜æ–¹å®ç°ï¼šhttps://pytorch.ac.cn/tutorials/beginner/torchtext_translation.html
PyTorchå®˜æ–¹å®ç°ä¸­æ–‡ï¼šhttps://github.com/apachecn/apachecn-dl-zh/blob/master/docs/pt-tut-17/32.md
PyTorchå®˜æ–¹ç¤ºä¾‹ï¼šhttps://github.com/pytorch/examples/blob/main/language_translation/src/model.py

ï¼ˆä¸å…¨ï¼‰https://github.com/BrightXiaoHan/MachineTranslationTutorial/blob/master/tutorials/Chapter2/Normalize.md


æœºå™¨ç¿»è¯‘ï¼ˆmachine translationï¼‰æŒ‡çš„æ˜¯ å°†åºåˆ—ä»ä¸€ç§è¯­è¨€è‡ªåŠ¨ç¿»è¯‘æˆå¦ä¸€ç§è¯­è¨€ã€‚ äº‹å®ä¸Šï¼Œè¿™ä¸ªç ”ç©¶é¢†åŸŸå¯ä»¥è¿½æº¯åˆ°æ•°å­—è®¡ç®—æœºå‘æ˜åä¸ä¹…çš„20ä¸–çºª40å¹´ä»£ï¼Œ ç‰¹åˆ«æ˜¯åœ¨ç¬¬äºŒæ¬¡ä¸–ç•Œå¤§æˆ˜ä¸­ä½¿ç”¨è®¡ç®—æœºç ´è§£è¯­è¨€ç¼–ç ã€‚ å‡ åå¹´æ¥ï¼Œåœ¨ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œç«¯åˆ°ç«¯å­¦ä¹ çš„å…´èµ·ä¹‹å‰ï¼Œ ç»Ÿè®¡å­¦æ–¹æ³•åœ¨è¿™ä¸€é¢†åŸŸä¸€ç›´å æ®ä¸»å¯¼åœ°ä½ (Brown et al., 1990, Brown et al., 1988)ã€‚ å› ä¸ºç»Ÿè®¡æœºå™¨ç¿»è¯‘ï¼ˆstatistical machine translationï¼‰æ¶‰åŠäº† ç¿»è¯‘æ¨¡å‹å’Œè¯­è¨€æ¨¡å‹ç­‰ç»„æˆéƒ¨åˆ†çš„ç»Ÿè®¡åˆ†æï¼Œ å› æ­¤åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•é€šå¸¸è¢«ç§°ä¸º `ç¥ç»æœºå™¨ç¿»è¯‘`ï¼ˆneural machine translationï¼‰ï¼Œ ç”¨äºå°†ä¸¤ç§ç¿»è¯‘æ¨¡å‹åŒºåˆ†å¼€æ¥ã€‚

+ ä»»åŠ¡è¯´æ˜ï¼š<br>
ï¼ˆ1ï¼‰åŸºäºåºåˆ—åˆ°åºåˆ—ï¼ˆSeq2Seqï¼‰å­¦ä¹ æ¡†æ¶ï¼Œè®¾è®¡å¹¶è®­ç»ƒä¸€ä¸ªä¸­è‹±æ–‡æœºå™¨ç¿»è¯‘æ¨¡å‹ï¼Œå®Œæˆä¸­è¯‘è‹±å’Œè‹±è¯‘ä¸­ç¿»è¯‘ä»»åŠ¡ã€‚å…·ä½“æ¨¡å‹é€‰æ‹©å¯ä»¥å‚è€ƒå¦‚ LSTMï¼ŒGRUï¼ŒTransformer ç­‰ï¼›<br>
ï¼ˆ2ï¼‰æ ¹æ®æŒ‡å®šçš„è¯„ä»·æŒ‡æ ‡å’Œæµ‹è¯•é›†æ•°æ®è¯„ä»·æ¨¡å‹æ€§èƒ½ã€‚

+ è¯„ä»·æŒ‡æ ‡ï¼š
ï¼ˆ1ï¼‰BLEU1/2/3ï¼šBLEUï¼ˆBilingual Evaluation Understudyï¼‰è®¡ç®—åŒæ—¶å‡ºç°åœ¨ç³»ç»Ÿè¯‘æ–‡å’Œå‚è€ƒè¯‘æ–‡ä¸­çš„ n å…ƒè¯é‡å ç¨‹åº¦ï¼Œå®éªŒè¦æ±‚è®¡ç®— n=1/2/3ã€‚
ï¼ˆ2ï¼‰Perplexityï¼šPerplexity æ˜¯è¡¡é‡è¯­è¨€æ¨¡å‹ç”Ÿæˆå¥å­èƒ½åŠ›çš„è¯„ä»·æŒ‡æ ‡

+ æ•°æ®è¯´æ˜<br>
å®éªŒæ•°æ®é›†ä¸º WMT18 æ–°é—»è¯„è®ºæ•°æ®é›† [News Commentary v13](http://data.statmt.org/wmt18/translation-task/training-parallel-nc-v13.tgz)<br>
åŒ…å«ä¸­è‹±æ–‡å¹³è¡Œè¯­æ–™ä¸¤ä¸ªæ–‡ä»¶ï¼š `news-commentary-v13.zh-en.en`ã€`news-commentary-v13.zh-en.zh`<br>
æ•´ä¸ªè¯­æ–™åº“åˆ†è®­ç»ƒé›†ï¼ˆçº¦ 176943 æ¡ï¼‰ã€éªŒè¯é›†ï¼ˆçº¦25278æ¡ï¼‰å’Œæµ‹è¯•é›†ï¼ˆçº¦ 50556 æ¡ï¼‰ä¸‰éƒ¨åˆ†ï¼Œå³æŒ‰7:1:2çš„æ¯”ä¾‹è¿›è¡Œåˆ‡åˆ†ï¼›<br>

+ æ•°æ®ç¤ºä¾‹<br>
```

```

[HAMI-core Msg(813:140699094931264:libvgpu.c:836)]: Initializing.....
Fri May  2 07:22:52 2025
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 470.57.02    Driver Version: 470.57.02    CUDA Version: 12.2     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-PCI...  Off  | 00000000:65:00.0 Off |                    0 |
| N/A   44C    P0    74W / 250W |  26940MiB / 40536MiB |     40%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+


[1] [åŠ¨æ‰‹æ·±åº¦å­¦ä¹ v2-æœºå™¨ç¿»è¯‘ä¸æ•°æ®é›†](https://zh.d2l.ai/chapter_recurrent-modern/machine-translation-and-dataset.html)<br>








å¯¹æ¯”ä¸åŒåˆ†è¯çš„å½±å“
spacy
https://www.cnblogs.com/luohenyueji/p/17584672.html
```python
import spacy

# åŠ è½½å·²å®‰è£…çš„ä¸­æ–‡æ¨¡å‹
nlp = spacy.load('zh_core_web_sm')

# æ‰§è¡Œä¸€äº›ç®€å•çš„NLPä»»åŠ¡
doc = nlp("æ—©ä¸Šå¥½!")
for token in doc:
    # token.textè¡¨ç¤ºæ ‡è®°çš„åŸå§‹æ–‡æœ¬ï¼Œtoken.pos_è¡¨ç¤ºæ ‡è®°çš„è¯æ€§ï¼ˆpart-of-speechï¼‰ï¼Œtoken.dep_è¡¨ç¤ºæ ‡è®°ä¸å…¶ä»–æ ‡è®°ä¹‹é—´çš„å¥æ³•ä¾å­˜å…³ç³»
    print(token.text, token.pos_, token.dep_)

import spacy

nlp = spacy.load("en_core_web_sm")
doc = nlp("Apple is looking at buying U.K. startup for $1 billion")
for token in doc:
    print(token.text)
```

Byte-BPE
HuggingFace ByteLevelBPETokenizerï¼š from tokenizers import ByteLevelBPETokenizer
OpenAI GPT Tokenizer: https://github.com/openai/tiktoken

Bert-wordpiece
tokenizer = BertTokenizer.from_pretrained("bert-base-chinese")
tokenizer.save_pretrained(model_path)

sentencepiece
https://github.com/google/sentencepiece



### é—®é¢˜è®°å½•
Windows æŠ¥é”™
```
Traceback (most recent call last):
  File "E:\PycharmProjects\llm-learning\llm-00-foundation\03-transformer\translation\dataset.py", line 9, in <module>
    from torchtext.data import get_tokenizer
  File "E:\PythonEnvs\llm-learning\lib\site-packages\torchtext\__init__.py", line 18, in <module>
    from torchtext import _extension  # noqa: F401
  File "E:\PythonEnvs\llm-learning\lib\site-packages\torchtext\_extension.py", line 64, in <module>
    _init_extension()
  File "E:\PythonEnvs\llm-learning\lib\site-packages\torchtext\_extension.py", line 58, in _init_extension
    _load_lib("libtorchtext")
  File "E:\PythonEnvs\llm-learning\lib\site-packages\torchtext\_extension.py", line 50, in _load_lib
    torch.ops.load_library(path)
  File "E:\PythonEnvs\llm-learning\lib\site-packages\torch\_ops.py", line 1295, in load_library
    ctypes.CDLL(path)
  File "E:\PythonEnvs\llm-learning\lib\ctypes\__init__.py", line 374, in __init__
    self._handle = _dlopen(self._name, mode)
OSError: [WinError 127] æ‰¾ä¸åˆ°æŒ‡å®šçš„ç¨‹åºã€‚
```
åŸå› ï¼štorchä¸torchtextç‰ˆæœ¬çš„å…¼å®¹é—®é¢˜
torch2.4.1ç‰ˆæœ¬è¿‡é«˜ï¼Œé™è‡³2.3.0ï¼Œæœ€ç»ˆé—®é¢˜è§£å†³ã€‚
https://blog.csdn.net/bcxbdzh/article/details/144276080


### æ©ç ç›¸å…³é—®é¢˜
æ³¨æ„åŠ›åˆ†æ•°(batch_size, num_heads, seq_len_q, seq_len_k)
æ‰€ä»¥ï¼š
1. ç¼–ç å™¨æ©ç ï¼ˆæ­£ç¡®ï¼‰
å¡«å……æ©ç å½¢çŠ¶ï¼š(batch_size, 1, 1, seq_len_src)
åˆç†æ€§ï¼šç¼–ç å™¨çš„é”®ï¼ˆKï¼‰æ¥è‡ªæºåºåˆ—ï¼Œéœ€å±è”½å¡«å……ä½ç½®ï¼ˆå¦‚<pad>ï¼‰ã€‚
å®ç°é€»è¾‘ï¼šé€šè¿‡æ‰©å±•æ©ç ç»´åº¦è‡³ (batch_size, num_heads, seq_len_q, seq_len_k)ï¼Œå®é™…è®¡ç®—æ—¶è‡ªåŠ¨å¹¿æ’­åˆ°æ‰€æœ‰å¤´å’ŒæŸ¥è¯¢ä½ç½®ã€‚

2. è§£ç å™¨è‡ªæ³¨æ„åŠ›æ©ç ï¼ˆéƒ¨åˆ†éœ€ä¿®æ­£ï¼‰
- å¡«å……æ©ç å½¢çŠ¶ï¼š(batch_size, 1, 1, seq_len_tgt)
åˆç†æ€§ï¼šç›®æ ‡åºåˆ—çš„å¡«å……ä½ç½®éœ€å±è”½ï¼Œä½†éœ€å¹¿æ’­åˆ°æŸ¥è¯¢ç»´åº¦ã€‚
ä¿®æ­£å»ºè®®ï¼šå®é™…åº”ç”¨ä¸­éœ€å°†æ©ç æ‰©å±•ä¸º (batch_size, 1, seq_len_tgt, seq_len_tgt)ï¼Œç¡®ä¿æ¯ä¸ªæŸ¥è¯¢ä½ç½®å‡è¿‡æ»¤æ— æ•ˆé”®ã€‚
- å‰ç»æ©ç ï¼ˆå› æœæ©ç ï¼‰å½¢çŠ¶ï¼š(batch_size, 1, seq_len_tgt, seq_len_tgt)
åˆç†æ€§ï¼šä¸‹ä¸‰è§’çŸ©é˜µä¸¥æ ¼é˜²æ­¢æœªæ¥ä¿¡æ¯æ³„éœ²ï¼Œä¸æ ‡å‡†Transformerå®ç°ä¸€è‡´ã€‚
æœ¯è¯­ä¿®æ­£ï¼šå»ºè®®ä½¿ç”¨**â€œå› æœæ©ç â€**è€Œéâ€œå‰ç»æ©ç â€ï¼Œé¿å…æ­§ä¹‰ï¼ˆå‰ç»æ©ç å¯èƒ½æŒ‡å…è®¸æœ‰é™æœªæ¥è®¿é—®ï¼‰ã€‚
- åºåˆ—æ©ç åˆå¹¶é€»è¾‘ï¼šå¡«å……æ©ç  & å› æœæ©ç 
æ“ä½œæ­¥éª¤ï¼š
å°†å¡«å……æ©ç ä» (batch_size, 1, 1, seq_len_tgt) å¹¿æ’­è‡³ (batch_size, 1, seq_len_tgt, seq_len_tgt)ã€‚
ä¸å› æœæ©ç æŒ‰ä½ä¸æ“ä½œï¼Œç”Ÿæˆæœ€ç»ˆæ©ç  (batch_size, 1, seq_len_tgt, seq_len_tgt)ã€‚

3. è§£ç å™¨äº¤å‰æ³¨æ„åŠ›æ©ç ï¼ˆæ­£ç¡®ï¼‰
æ©ç å½¢çŠ¶ï¼š(batch_size, 1, 1, seq_len_src)
åˆç†æ€§ï¼šäº¤å‰æ³¨æ„åŠ›ä¸­ï¼Œé”®ï¼ˆKï¼‰æ¥è‡ªç¼–ç å™¨è¾“å‡ºï¼Œéœ€åº”ç”¨æºåºåˆ—çš„å¡«å……æ©ç ã€‚
å®ç°é€»è¾‘ï¼šæ©ç å¹¿æ’­è‡³ (batch_size, num_heads, seq_len_tgt, seq_len_src)ï¼Œç¡®ä¿è§£ç å™¨æ¯ä¸ªæŸ¥è¯¢ä»…å…³æ³¨æœ‰æ•ˆæºä½ç½®ã€‚

https://www.cvmart.net/community/detail/5137
https://avoid.overfit.cn/post/2371a9ec5eca46af81dbe23d3442a383
https://ifwind.github.io/2021/08/17/Transformer%E7%9B%B8%E5%85%B3%E2%80%94%E2%80%94%EF%BC%887%EF%BC%89Mask%E6%9C%BA%E5%88%B6/#unilm%E4%B8%AD%E7%9A%84mask

#### é—®é¢˜

1. ä¸ºä½•ä¸å¯¹æŸ¥è¯¢ï¼ˆQï¼‰æ©ç ï¼Ÿ
åŠŸèƒ½åˆ†ç¦»ï¼šQä»£è¡¨å½“å‰éœ€è¦â€œæé—®â€çš„ä½ç½®ï¼ˆå¦‚è§£ç å™¨å½“å‰ç”Ÿæˆè¯ï¼‰ï¼ŒK/Vä»£è¡¨å¯æ£€ç´¢çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚
è®¡ç®—æ•ˆç‡ï¼šè‹¥å¯¹Qæ©ç ï¼Œéœ€é€ä¸ªåˆ¤æ–­å…¶æœ‰æ•ˆæ€§ï¼Œå¢åŠ å¤æ‚åº¦ï¼›æ©ç Kå¯ä¸€æ¬¡æ€§å±è”½æ‰€æœ‰æ— æ•ˆä¸Šä¸‹æ–‡ã€‚
æ¨¡å‹é²æ£’æ€§ï¼šå³ä½¿Qæ¥è‡ªå¡«å……ä½ç½®ï¼ˆå¦‚ç¼–ç å™¨çš„æ— æ•ˆè¯ï¼‰ï¼Œå…¶è¾“å‡ºä¼šè¢«åç»­å¤„ç†ï¼ˆå¦‚æ± åŒ–å±‚ï¼‰è¿‡æ»¤ï¼Œæ— éœ€é¢å¤–æ“ä½œã€‚
2. ä¸ºä½•å¡«å……æ©ç ä»…ä½œç”¨äºKï¼Ÿ
æ³¨æ„åŠ›æƒé‡æœ¬è´¨ï¼šæ³¨æ„åŠ›åˆ†æ•°è¡¨ç¤ºæŸ¥è¯¢ä¸é”®çš„å…³è”æ€§ã€‚è‹¥KåŒ…å«å¡«å……ä½ç½®ï¼Œéœ€å…¨å±€å±è”½è¿™äº›æ— æ•ˆå…³è”ï¼Œè€Œéé™åˆ¶æŸ¥è¯¢çš„ä¸»åŠ¨æ€§ã€‚
ç»Ÿä¸€è¿‡æ»¤é€»è¾‘ï¼šæ‰€æœ‰æŸ¥è¯¢ï¼ˆæ— è®ºæœ‰æ•ˆä¸å¦ï¼‰å‡ä¸å…³æ³¨å¡«å……ä½ç½®ï¼Œé¿å…æ¨¡å‹å­¦ä¹ åˆ°è™šå‡ä¾èµ–ã€‚
