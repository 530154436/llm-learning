
## 第四章 数据准备

通过在大规模语料上进行`预训练`，大语言模型可以获得通用的语言理解与生成能力，掌握较为广泛的世界知识，具备解决众多下游任务的性能潜力。在这一过程中，预训练语料的规模和质量对于提升大语言模型的能力至关重要。<br>
预训练语料准备主要包含原始数据的收集、数据预处理、数据词元化、以及预训练过程中的数据调度方法。

### 4.1 数据来源

为了构建功能强大的大语言模型，需要从多元化的数据源中收集海量数据来进行训练。<br>
根据来源不同，预训练数据主要分为两种类型：通用文本数据和专用文本数据。`通用文本数据`涵盖了网页、书籍和对话文本等。由于通用文本数据规模较大、多样性强且易于获取，大多数大语言模型都会收集大量的通用文本数据，以增强其语言建模能力。此外，为了进一步提升大语言模型在特定专业任务上的表现，人们还将预训练语料的范围扩展至更`专业的数据集`，如多语数据、科学数据和代码数据等。

<img src="images/图 4.1 现有大语言模型预训练数据中各种数据来源的比例分布图.png" width="35%" height="35%" alt="">

#### 4.1.1 通用文本数据
+ **网页**<br>
使用大规模网页文本数据进行预训练，有助于大语言模型获取多样化的语言知识，并增强其自然语言理解和生成的能力。<br>
大规模网页数据集包括 C4、RefinedWeb、CC-Stories等。<br>
网页数据集中既包含了维基百科这种高质量文本，也不可避免地引入了广告网页等低质量文本。<br>
因此，在进行预训练之前，对网页进行筛选和处理显得尤为重要，这直接关系到最终数据的质量与预训练效果。<br>

+ **书籍**<br>
书籍文本在大语言模型的学习过程中，发挥着非常重要的作用，它们不仅能够帮助模型积累丰富的语言知识，还可以`加强其长程语义关系的建模`。
现有的研究工作通常使用 Books3 和 Bookcorpus2 等开源书籍数据集。<br>

#### 4.1.2 通用文本数据
+ **多语文本**<br>
在预训练语料中，加入多语言的文本数据可以增强模型的多语理解与生成能力。<br>
相比于仅针对单一目标语言进行微调的模型，在多语言语料库上训练过的大语言模型能够更好地建立`多语言间的语义关联`，为跨语言理解与对话任务提供支持。<br>
不仅如此，多语言数据还能有效增加数据的多样性，从而有助于提升模型的综合性能。

+ **科学文本**<br>
通过在大规模的科学文本语料上进行预训练，大语言模型可以在自然科学以及工程技术方面建立坚实的知识基础，从而在`科学问答与推理等任务`上取得出色的表现。<br>
构建科学文本语料的常用方法是收集 arXiv 论文、科学教材、数学网页等科学资源。<br>
然而，由于科学文本数据中包含数学公式、蛋白质序列等特殊符号，通常需要采用特定的分词和预处理技术，将这些不同格式的数据转化为大语言模型能够处理的统一格式。

+ **代码**<br>
为了提高模型的代码能力，需要在大量代码语料上进行预训练，进而提高其所生成的程序质量。<br>
一般来说，常用于大语言模型预训练的代码语料有两种来源，第一种是 Stack Exchange 等编程问答社区的数据，第二种是GitHub 等开源项目仓库。<br>
在代码数据上训练能够提升模型的`结构化语义理解`与`逻辑推理能力`。同时，代码中的函数调用关系还有助于增强模型的`工具使用与学习能力`。


### 4.2 数据预处理
当收集了丰富的文本数据之后，为了确保数据的质量和效用，还需要对数据进行`预处理`，从而消除低质量、冗余、无关甚可能有害的数据。（如开源库 `Data-Juicer`），

<img src="images/图 4.2 典型的预训练数据预处理流程图.png" width="50%" height="50%" alt="">


#### 4.2.1 质量过滤
为了优化模型学习的性能，需要去除语料库中的低质量数据。目前，研究人员主要使用以下两种数据清洗方法：（1）基于启发式规则的方法，和（2）基于分类器的方法。

##### 基于启发式规则的方法
+ `基于语种的过滤`<br>
为了训练特定目标语言为主导的大语言模型，通常要过滤掉其他语言的文本数据。<br>
需要注意的是，目前英文的高质量开放数据数量最多，已经成为了开源大语言模型的主要数据来源。<br>
因此，即使是训练非英文主导的大语言模型时（如中英双语大模型），不仅要保留特定目标语言数据，还需要同时保留英文高质量数据。

+ `基于简单统计指标的过滤`<br>
为了识别高质量的文本数据，可以使用语料中标点符号分布、符号与单词比率、句子长度等特征来衡量`文本质量`，并过滤低质量数据。<br>
除了这些统计特征以外，也可以利用`困惑度`（Perplexity）等文本生成的评估指标来检测和删除表达不自然的句子。<br>
1）针对网页数据，过滤任何具有超过 100 个重复单词或句子的文档（来源：Dolma）<br>
2）针对网页数据，过滤符号和词元比大于 0.1 的文档（来源：Gopher）<br>
3）针对论坛数据，过滤掉任何点赞数少于 3 的用户评论（来源：Dolma）<br>
4）利用已有的语言模型计算文档困惑度，并以此作为文档过滤的依据（来源：Dolma）<br>
5）训练 FastText 分类器来检测和删除有毒或仇恨言论的内容（来源：Dolma）<br>

+ `基于关键词的过滤`<br>
在收集到的预训练语料中，可能会存在着大量的重复文本模式，诸如常见的 HTML 标签、超链接以及各种模板等。<br>
进一步，这些语料中还可能包含了一些具有攻击性、冒犯性的不良信息。<br>
针对不同的语料来源以及应用场景，我们可以制定精准的清洗规则，结合相应的关键词集合，对文本进行扫描过滤。<br>
1）针对维基百科数据，过滤掉任何拥有少于 25 个 UTF-8 单词的页面。（来源：Dolma）
2）针对网页数据，过滤掉 HTML 标签（来源：RefinedWeb）
3）针对网页数据，过滤掉任何不含有 the, be, to, of, and, that, have, with 词汇的文档 （来源：Gopher）
4）针对所有数据，过滤掉如电话号码，邮箱地址，以及 IP 地址等隐私信息（来源：Dolma）

##### 基于分类器的方法

除了利用上述启发式的规则，我们也可以训练用于判别数据质量的文本分类器，进行预训练语料的清洗。
在选取样本时，可以将维基百科等高质量数据作为`正样本`，同时从网页中筛选出含有不良内容或低质量数据的样本作为`负样本`。
为了减少数据的误筛，可以使用`多个分类器进行联合过滤或召回`，从而来实现对低质量文本的高可信过滤。 

目前常用来实现分类器的方法包括轻量级模型（如 `FastText` 等）、可微调的预训练语言模型（如 BERT、BART 或者 LLaMA 等）以及闭源大语言模型 API（如GPT-4、Claude 3）。 
这三个方法各自具有不同的优缺点：轻量级模型效率较高，但是分类的准确率和精度可能受限于模型能力；预训练语言模型可以针对性微调，但是分类性能的通用性和泛化性仍然有一定的限制；闭源大语言模型的能力较强， 但是无法灵活针对任务进行适配，而且用于预训练数据清洗需要花费较高的成本。

为了平衡效率与准确性，可以针对具体数据集合进行清洗策略的灵活组合。例如，可以首先利用启发式规则进行初步筛选，以快速排除不符合要求的文档，随后再采用分类器方法进一步精细过滤，确保最终筛选出的语料具有较好的文本质量。


#### 4.2.2 敏感内容过滤
除了去除低质量内容，收集到的数据还可能包括`有毒内容`或`隐私信息`，需要进一步进行更为细致的过滤和处理。

+ `过滤有毒内容`<br>
可以采用基于分类器的过滤方法。 <br>
Jigsaw 评论数据集提供了用于训练毒性分类器的数据。（160K 条论坛评论数据，六个类别）<br>
通过设置合理的阈值，训练完成的分类器将能够有效识别并过滤掉含有有毒内容的信息。
使用高阈值时去除的数据会过少，语料中未过滤掉的有毒内容会导致模型在下游任务上的性能下降；而低阈值则会过滤更多的有毒内容，但同时也会造成大量数据的浪费。
考虑到后续的预处理操作（如质量筛选、去重等）同样能够有效剔除有害内容，Dolma 选择为分类器设定了一个相对较高的阈值（0.4），从而保留更多的候选数据。

+ `过滤隐私内容`<br>
Dolma 采用了基于规则的方法来过滤数据集中的隐私内容，主要标注了三类敏感信息：邮箱地址、IP 地址以及电话号码。<br>
如果某个文档中的隐私信息少于五条，Dolma 会使用特定的词元（如“|||EMAIL_ADDRESS|||”、“|||PHONE_NUMBER|||” 和“|||IP_ADDRESS|||”）来替换这些信息，以保护用户的隐私。
然而，如果文档中的隐私信息达到六条或更多，Dolma 会选择直接删除整个文档。这是因为当文档中频繁出现隐私信息时，很可能还隐藏着其他未标注的敏感内容。

#### 4.2.3 数据去重

由于大语言模型具有较强的`数据拟合`与`记忆能力`，很容易习得训练数据中的重复模式，可能导致对于这些模式的过度学习。
预训练语料中出现的重复低质量数据可能诱导模型在生成时频繁输出类似数据，进而影响模型的性能。此外，这些数据也可能导致训练过程的不稳定（训练损失震荡），可能导致训练过程崩溃。此外，为了避免数据集污染问题，还需要从预训练数据集中删除在测试集中可能出现的重复或者相关文本，从而防止训练集和测试集之间的重叠。 总体来说，去重算法的设计可以基于不同的计算粒度以及匹配方法。

+ `计算粒度`<br>
去重可以在句子级别、文档级别和数据集级别等多种粒度上进行。现有的数据集往往采用多阶段、多粒度的方式来实现高效的去重。首先针对数据集和文档级别进行去重，旨在去除那些具有高度相似甚至完全一致内容的文档，例如新闻数据集中包含相同的新闻文档。随后，可以进一步在句子级别实现更为精细的去重。

+ `用于去重的匹配方法`<br>
在去重过程中，可以使用精确匹配算法（即每个字符完全相同）或近似匹配算法（基于某种相似性度量）。对于精确匹配来说，通常使用后缀数组来匹配最小长度的完全相同子串。对于近似匹配来说，可以采用局部敏感哈希（Locality-Sensitive Hashing, LSH）算法，如最小哈希（MinHash）来实现。

#### 4.2.4 数据对预训练效果的影响
已有的研究表明，基于含有噪音、有毒和重复数据的低质量语料库进行预训练，会严重损害模型性能。

##### 数据数量的影响
整体上，`语言模型的性能会随着训练数据数量的增加而提升`，符合扩展法则。
一些更小尺寸的语言模型也使用了高达 1T 级别的数据进行了训练，发现其仍然没有达到语言模型能够学习的数据量上限。数据量的扩展性本质上来源于 Transformer 模型的可扩展性，这也是大语言模型能够取得成功最为关键的基础要素。

##### 数据质量的影响
在获取充足数量的预训练数据后，数据质量直接决定了模型的实际性能。通过显著提升数据质量，使得语言模型在参数、数据、算力更加节约的情况下就能展现出与更大规模模型相匹敌甚至更为优异的性能。

+ `整体影响`<br>
大语言模型所掌握的知识信息也来源于预训练数据，这意味着如果模型在包含事实性错误的、过时的数据上进行训练，那么它在处理相关主题时可能会产生不准确或虚假的信息，这种现象被称为“幻象” 。

+ `重复数据`<br>
重复数据也可能导致“双下降现象”，即模型训练损失先经历下降然后出现升高再下降的现象。此外，重复数据可能会降低大语言模型利用上下文中信息的能力。这会削弱模型在上下文学习中的泛化能力，使其难以适应各种复杂的语言环境和任务需求。随着模型参数规模的不断增加，公开可获取的数据将很快接近采集枯竭的状态，可以使用大语言模型对于稀缺数据进行改写或者针对性的生成。

+ `有偏、有毒、隐私内容`<br>
如果训练数据中包含有毒内容，模型则可能会产生侮辱性、攻击性或其他有害的输出；而在含有隐私内容的数据上训练可能会导致模型在输出中无意中泄露或利用个人数据。因此，在训练大语言模型之前，需要通过严格的数据过滤和预处理方法来尽量减少有偏见、有毒或包含隐私信息的数据。

##### 数据集污染
在进行模型评测时，可能会发现某些评估基准所包含的数据，实际上已出现在预训练数据或者微调数据中，这种现象被称为基准泄漏或`数据集污染`。数据集污染问题可能导致模型在与测试数据集相关甚至高度重合的语料上进行训练，从而原本用于衡量模型在少样本或零样本场景下的性能评测，转变为了领域内的测试任务。这种情况破坏了评估集合构建的初衷，使得不同模型之间的对比失去了公平性。


### 4.3 词元化（分词）


### 4.4 数据调度








