# 《大语言模型》读书笔记

本书共设置了五个主要部分，分别是背景与基础知识部分、预训练部分、微调与对齐部分、大模型使用部分以及评测与应用部分。

### 背景与基础知识部分

- **第2章**: 介绍大语言模型的构建过程，并讲解相关的背景知识和重要概念，如涌现能力、扩展定律及其联系与区别。进一步探讨GPT系列模型的发展历程及各个阶段的重要技术创新，帮助读者理解大语言模型的技术升级历史。
- **第3章**: 汇总大语言模型相关的资源信息，包括公开可用的模型检查点与API、数据集合以及代码工具库，为读者提供全面的资源梳理。

### 预训练部分

- **第4章**: 主要介绍预训练数据的准备工作，涵盖数据的收集、清洗以及词元化方法，并讨论数据课程的设计方法。
- **第5章**: 详细介绍大语言模型的架构，包括Transformer模型、各种组件的详细配置、长文本建模以及一些新型的模型架构。
- **第6章**: 讲解预训练过程中涉及的预训练任务、优化参数设置、可扩展的训练技术以及参数量计算与效率分析方法，并通过实战代码进行演示。

### 微调与对齐部分

- **第7章**: 介绍指令微调涉及的数据构建和优化策略，探讨典型的轻量化微调技术以减少模型训练开销，并通过实践示例展示指令微调的具体流程。
- **第8章**: 详细介绍大模型的人类对齐技术，重点介绍基于`RLHF`的方法，并进一步探讨`非强化学习的对齐方法`，最后讨论SFT与RLHF之间的关系。

### 大模型使用部分

- **第9章**: 介绍大模型的解码与部署方法，包括解码策略、解码加速算法、低资源部署策略以及其他模型压缩方法。
- **第10章**: 探讨面向大语言模型的提示学习技术，涵盖基础的提示学习设计方法、上下文学习方法以及思维链方法等。
- **第11章**: 探索如何将复杂任务进行有效分解，并通过回溯、反思等关键技术形成有效的解决方案；进一步介绍如何构建基于大语言模型的`智能体`以及`多智能体系统`。

### 评测与应用部分

- **第12章**: 介绍面向大语言模型性能的评测方法，针对不同的能力维度讲解相关的评测集合、评测指标以及评测方法，并指出大语言模型目前存在的问题。
- **第13章**: 从代表性的研究领域和应用领域两个维度展开讨论大语言模型的应用情况，以代表性工作为驱动，使读者了解如何将大语言模型进行领域特化和任务特化。
- **第14章**: 总结全文内容，梳理每个部分存在的技术挑战和研究趋势。

### 引用
赵鑫, 李军毅, 周昆, 唐天一, 和 文继荣. [大语言模型](https://llmbook-zh.github.io/). 高等教育出版社, 2024, 北京. 
配套代码：
[LLMBox](https://github.com/RUCAIBox/LLMBox/tree/main) 是作者团队围绕英文综述论文所开发的综合性大语言模型代码库，用于支持大模型训练与评测的学术研究工作。
[YuLan-Chat-3](https://github.com/RUC-GSAI/YuLan-Chat) 经历了完整的从头预训练、指令微调以及人类对齐的训练过程，包含 12B 的参数规模，预训练数据量达到 1.68T 词元。
[YuLan-Mini](https://github.com/RUC-GSAI/YuLan-Mini) YuLan-Mini 是一个 2.4B 参数量的轻量化语言模型。


大语言模型：从理论到实践（第二版）
https://intro-llm.github.io/
https://github.com/intro-llm/intro-llm-code

大语言模型训练数据(2024.11.12)
https://arxiv.org/html/2411.07715v1

数据处理框架
https://github.com/modelscope/data-juicer/blob/main/README_ZH.md
https://github.com/FlagOpen/FlagData/tree/main

语种检测
https://github.com/RUC-GSAI/Yulan-GARDEN/blob/main/utils/evaluator/LangIdentifier.py
https://github.com/apachecn/fasttext-doc-zh/blob/master/doc/zh/language-identification.md
https://fasttext.apachecn.org/#/doc/zh/language-identification
https://blog.csdn.net/weixin_45114252/article/details/111053988
