【4月学习计划】
1、大模型预训练部分了解+熟悉
2、tokenization+transformer 系统学习

[20250328-20250330]
[x] 1、大语言模型.赵鑫-ch04笔记总结、ch05-ch06泛读

[20250409-20250416]
[x] 1、流量控制算法实现和总结（分布式高并发场景）
[x] 2、tokenizer算法总结+huggingface ch06
https://huggingface.co/learn/nlp-course/zh-CN/chapter6/2?fw=pt
[x] 概述总结
[x] BPE
[x] WordPiece
[x] Unigram
[x] 维特比算法、EM算法总结

[20250413-20250427]
目标：掌握transformer
[95%] 1、论文学习：Attention is all you need
[x] Scaled Dot-Product Attention
[x] Self-Attention
[x] Cross-Attention
[x] MultiHead-Attention
[x] Position-wise Feed-Forward Networks
[x] Residual connection（残差连接）
[x] LayerNorm
[x] Add & Norm（子层链接: 残差连接+LayerNorm）
[x] Embedding
[x] Positional Encoding（位置编码）
[x] Mask
[x] Encoder
[x] Decoder
[x] Transformer

[95%] 2、各组件原理和实现
https://github.com/Hoper-J/AI-Guide-and-Demos-zh_CN/tree/master/PaperNotes
https://github.com/intro-llm/intro-llm-code/tree/main/chs/ch2-foundations/Transformer
https://nlp.seas.harvard.edu/annotated-transformer/#part-1-model-architecture

3、应用案例
[x] 1、人造数据测试
[0%] 2、英-中翻译（结合目前项目）

[20250428-20250505]
1、论文学习：Bert
2、各组件原理和实现
3、深度自然语言处理
https://blog.showmeai.tech/cs224n/
https://github.com/datawhalechina/learn-nlp-with-transformers
https://huggingface.co/learn/nlp-course/zh-CN/chapter1/1


【5月份学习计划】
《大语言模型：从理论到实践v2.2025.张奇》
大模型基础
大语言模型预训练
分布式训练
1、指令微调
NLLB-200 翻译大模型
2、Agent（大模型智能体）
吴恩达的translation-agent梳理、复现
mcp
a2a
langmanus
openmanus
3、RAG（检索增强生成）
基础RAG
GRAPH RAG
4、深度学习+PyTorch
5、李宏毅2024春《生成式人工智能导论》
https://www.bilibili.com/video/BV1BJ4m1e7g8
