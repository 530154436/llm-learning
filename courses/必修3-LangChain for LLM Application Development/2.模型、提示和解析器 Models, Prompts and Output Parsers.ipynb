{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 第二章 模型，提示和输出解释器\n",
    "\n",
    " - [一、设置OpenAI API Key](#一、设置OpenAI-API-Key)\n",
    " - [二、直接使用OpenAI](#二、直接使用OpenAI)\n",
    "     - [2.1 计算1+1](#2.1-计算1+1)\n",
    "     - [2.2 用美式英语表达海盗邮件](#2.2-用美式英语表达海盗邮件)\n",
    "     - [2.3 中文版](#2.3-中文版)\n",
    " - [三、通过LangChain使用OpenAI](#三、通过LangChain使用OpenAI)\n",
    "     - [3.1 模型](#3.1-模型)\n",
    "     - [3.2 提示模板](#3.2-提示模板)\n",
    "         - [3.2.1 使用LangChain提示模版](#3.2.1-使用LangChain提示模版)\n",
    "         - [3.2.2 为什么需要提示模版](#3.2.2-为什么需要提示模版)\n",
    "     - [3.3 输出解析器](#3.3-输出解析器)\n",
    "         - [3.3.1 如果没有输出解析器](#3.3.1-如果没有输出解析器)\n",
    "         - [3.3.2 LangChain输出解析器](#3.3.3-LangChain输出解析器)\n",
    " - [四、补充材料](#四、补充材料)\n",
    "     - [4.1 链式思考推理(ReAct)](#4.1-链式思考推理(ReAct))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 一、设置OpenAI API Key\n",
    "\n",
    "登陆 [OpenAI 账户](https://platform.openai.com/account/api-keys) 获取API Key，然后将其设置为环境变量。\n",
    "\n",
    "- 如果你想要设置为全局环境变量，可以参考[知乎文章](https://zhuanlan.zhihu.com/p/627665725)。\n",
    "- 如果你想要设置为本地/项目环境变量，在本文件目录下创建`.env`文件, 打开文件输入以下内容。\n",
    "\n",
    "    <p style=\"font-family:verdana; font-size:12px;color:green\">\n",
    "    OPENAI_API_KEY=\"your_api_key\" \n",
    "    </p>\n",
    "  \n",
    "  替换\"your_api_key\"为你自己的 API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from src.utils.chat_robot import OpenAiChat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 二、直接使用OpenAI\n",
    "\n",
    "我们先从直接调用OpenAI的API开始。\n",
    "\n",
    "`get_completion`函数是基于`openai`的封装函数，对于给定提示（prompt）输出相应的回答。其包含两个参数\n",
    "   \n",
    "   - `prompt` 必需输入参数。 你给模型的**提示，可以是一个问题，可以是你需要模型帮助你做的事**（改变文本写作风格，翻译，回复消息等等）。\n",
    "   - `model` 非必需输入参数。默认使用gpt-3.5-turbo。你也可以选择其他模型。\n",
    "   \n",
    "这里的提示对应我们给chatgpt的问题，函数给出的输出则对应chatpgt给我们的答案。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.1 计算1+1\n",
    "\n",
    "我们来一个简单的例子 - 分别用中英文问问模型\n",
    "\n",
    "- 中文提示(Prompt in Chinese)： `1+1是什么？`\n",
    "- 英文提示(Prompt in English)： `What is 1+1?`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'1+1等于2。'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 中文\n",
    "OpenAiChat().get_completion(\"1+1是什么？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2.2 用美式英语表达海盗邮件\n",
    "\n",
    "上面的简单例子，模型`gpt-3.5-turbo`对我们的关于1+1是什么的提问给出了回答。\n",
    "\n",
    "现在我们来看一个复杂一点的例子： \n",
    "\n",
    "假设我们是电商公司员工，顾客A在我们的网站上买了一个榨汁机用来做奶昔，在制作奶昔的过程中，奶昔的盖子飞了出去，弄得厨房墙上到处都是。于是顾客A给我们的客服中心写来以下邮件：`customer_email`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "customer_email = \"\"\"\n",
    "Arrr, I be fuming that me blender lid \\\n",
    "flew off and splattered me kitchen walls \\\n",
    "with smoothie! And to make matters worse,\\\n",
    "the warranty don't cover the cost of \\\n",
    "cleaning up me kitchen. I need yer help \\\n",
    "right now, matey!\n",
    "\"\"\"\n",
    "\n",
    "# 东北话\n",
    "customer_email_zh = \"\"\"\n",
    "哎呀妈呀，我都气坏了，我那搅拌机盖子飞出去，把厨房墙上弄得全是奶昔！\\\n",
    "更糟糕的是，这保修还不包清理厨房的费用。哥们儿，我现在真得需要你帮忙啊！\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "我们的客服人员对于方言措辞表达觉得有点难以理解。 现在我们想要实现两个小目标：\n",
    "\n",
    "- 让模型用普通话对邮件进行翻译以便客服人员可以更好理解。\n",
    "- 让模型在翻译是用平和尊重的语气进行表达，客服人员的心情也会更好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "把由三个反引号分隔的文本翻译成一种正式的普通话和冷静且尊重的语气的风格。\n",
      "文本:\n",
      "```\n",
      "哎呀妈呀，我都气坏了，我那搅拌机盖子飞出去，把厨房墙上弄得全是奶昔！更糟糕的是，这保修还不包清理厨房的费用。哥们儿，我现在真得需要你帮忙啊！\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 定义文本表达风\n",
    "style = \"正式的普通话和冷静且尊重的语气\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "把由三个反引号分隔的文本翻译成一种{style}的风格。\n",
    "文本:\n",
    "```{customer_email_zh}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'尊敬的先生/女士，\\n\\n我感到非常不安，因为我的搅拌机盖子飞出去了，导致厨房墙壁上都是奶昔。更糟糕的是，保修不包括清理厨房的费用。我真的需要您的帮助，希望您能给予支持。感谢您的理解和合作。\\n\\n谢谢。'"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = OpenAiChat().get_completion(prompt)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "对比语言风格转换前后，用词更为正式，替换了极端情绪的表达，并表达了感谢。\n",
    "\n",
    "✨ 你可以尝试修改提示，看可以得到什么不一样的结果😉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 三、通过LangChain使用OpenAI\n",
    "\n",
    "在前面一部分，我们通过封装函数`get_completion`直接调用了OpenAI完成了对方言邮件进行了的翻译，得到用平和尊重的语气、正式的普通话表达的邮件。\n",
    "\n",
    "让我们尝试使用LangChain来实现相同的功能。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.1 模型\n",
    "\n",
    "从`langchain.chat_models`导入`OpenAI`的对话模型`ChatOpenAI`。 除去OpenAI以外，`langchain.chat_models`还集成了其他对话模型，更多细节可以查看[Langchain官方文档](https://python.langchain.com/en/latest/modules/models/chat/integrations.html)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_openai.chat_models.base.ChatOpenAI'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x1357863e0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13578f310>, temperature=0.0, openai_api_key=SecretStr('**********'), openai_api_base='https://api.chatanywhere.com.cn/v1', openai_proxy='')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 这里我们将参数temperature设置为0.0，从而减少生成答案的随机性。\n",
    "# 如果你想要每次得到不一样的有新意的答案，可以尝试调整该参数。\n",
    "\n",
    "api_key = os.environ.get(\"CHAT_ANYWHERE_API_KEY\")\n",
    "base_url = \"https://api.chatanywhere.com.cn/v1\"\n",
    "chat = ChatOpenAI(temperature=0.0, base_url=base_url, api_key=api_key)\n",
    "print(type(chat))\n",
    "chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.2 提示模版\n",
    "\n",
    "#### 3.2.1 使用LangChain提示模版\n",
    "\n",
    "\n",
    "何使用`langchain`来构造提示。\n",
    "\n",
    "1. 构造提示模版字符串：`template_string`\n",
    "2. 构造LangChain提示模版\n",
    "调用`ChatPromptTemplate.from_template()`函数\n",
    "=> 得到提示模版`prompt_template`\n",
    "3. 使用模版得到客户消息提示\n",
    "langchain提示模版`prompt_template`需要两个输入变量： `style` 和 `text`。 这里分别对应\n",
    "`customer_style`: 我们想要的顾客邮件风格\n",
    "`customer_email_zh`: 顾客的原始邮件文本。\n",
    "=> 得到`customer_messages`变量类型为列表(`list`)，每个元素变量类型为(`langchain.schema.HumanMessage`)。\n",
    "\n",
    "4. 调用chat模型转换客户消息风格\n",
    "调用[模型](#model)部分定义的chat模型来实现转换客户消息风格。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.chat.ChatPromptTemplate'>\n",
      "<class 'list'>\n",
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['style', 'text'] template='\\n把由三个反引号分隔的文本翻译成这种风格：{style}。\\n文本:\\n```{text}```\\n'\n",
      "<class 'list'>\n",
      "<class 'langchain_core.messages.human.HumanMessage'>\n",
      "content='\\n把由三个反引号分隔的文本翻译成这种风格：正式的普通话和冷静且尊重的语气。\\n文本:\\n```\\n哎呀妈呀，我都气坏了，我那搅拌机盖子飞出去，把厨房墙上弄得全是奶昔！更糟糕的是，这保修还不包清理厨房的费用。哥们儿，我现在真得需要你帮忙啊！\\n```\\n'\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='尊敬的先生/女士，我感到非常不安，因为我的搅拌机盖子飞出去了，导致厨房墙壁上都是奶昔。更糟糕的是，保修不包括清理厨房的费用。尊敬的先生/女士，我真的需要您的帮助。感谢您的理解与支持。' response_metadata={'token_usage': {'completion_tokens': 117, 'prompt_tokens': 165, 'total_tokens': 282}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-5b50143f-4928-46b5-a97f-0b87255e97bf-0' usage_metadata={'input_tokens': 165, 'output_tokens': 117, 'total_tokens': 282}\n"
     ]
    },
    {
     "data": {
      "text/plain": "'尊敬的先生/女士，我感到非常不安，因为我的搅拌机盖子飞出去了，导致厨房墙壁上都是奶昔。更糟糕的是，保修不包括清理厨房的费用。尊敬的先生/女士，我真的需要您的帮助。感谢您的理解与支持。'"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "customer_email_zh = \"\"\"\n",
    "哎呀妈呀，我都气坏了，我那搅拌机盖子飞出去，把厨房墙上弄得全是奶昔！\\\n",
    "更糟糕的是，这保修还不包清理厨房的费用。哥们儿，我现在真得需要你帮忙啊！\n",
    "\"\"\"\n",
    "customer_style = \"正式的普通话和冷静且尊重的语气\"\n",
    "template_string = \"\"\"\n",
    "把由三个反引号分隔的文本翻译成这种风格：{style}。\n",
    "文本:\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "# 构造LangChain提示模版\n",
    "prompt_template: ChatPromptTemplate = ChatPromptTemplate.from_template(template_string)\n",
    "print(type(prompt_template))\n",
    "print(type(prompt_template.messages))\n",
    "print(type(prompt_template.messages[0].prompt))\n",
    "print(prompt_template.messages[0].prompt)\n",
    "\n",
    "# 使用模版得到客户消息提示\n",
    "customer_messages: HumanMessage = prompt_template.format_messages(style=style,\n",
    "                                                    text=customer_email_zh)\n",
    "print(type(customer_messages))\n",
    "print(type(customer_messages[0]))\n",
    "print(customer_messages[0])\n",
    "\n",
    "# 调用chat模型转换客户消息风格\n",
    "customer_response: AIMessage = chat.__call__(customer_messages)\n",
    "print(type(customer_response))\n",
    "print(customer_response)\n",
    "customer_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "使用第2步构造的langchain提示模版，来获得我们回复消息提示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "把由三个反引号分隔的文本翻译成这种风格：一个有礼貌的语气 使用正式的普通话 。\n",
      "文本:\n",
      "```嘿，顾客， 保修不包括厨房的清洁费用， 因为您在启动搅拌机之前 忘记盖上盖子而误用搅拌机, 这是您的错。 倒霉！ 再见！\n",
      "```\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "'尊敬的顾客，很抱歉通知您，根据保修条款，厨房清洁费用不在保修范围内。这是因为在使用搅拌机时，您忘记盖上盖子而导致误用搅拌机，这属于您的责任范畴。希望您能理解。祝您好运，再见。'"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "service_reply = \"\"\"嘿，顾客， \\\n",
    "保修不包括厨房的清洁费用， \\\n",
    "因为您在启动搅拌机之前 \\\n",
    "忘记盖上盖子而误用搅拌机, \\\n",
    "这是您的错。 \\\n",
    "倒霉！ 再见！\n",
    "\"\"\"\n",
    "\n",
    "service_style_pirate = \"\"\"\\\n",
    "一个有礼貌的语气 \\\n",
    "使用正式的普通话 \\\n",
    "\"\"\"\n",
    "service_messages = prompt_template.format_messages(\n",
    "    style=service_style_pirate,\n",
    "    text=service_reply)\n",
    "\n",
    "print(service_messages[0].content)\n",
    "\n",
    "\n",
    "service_response = chat.__call__(service_messages)\n",
    "service_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.2.2 为什么需要提示模版\n",
    "\n",
    "在应用于比较复杂的场景时，提示可能会非常长并且包含涉及许多细节。**使用提示模版，可以让我们更为方便地重复使用设计好的提示**。下面给出了一个比较长的提示模版案例。学生们线上学习并提交作业，通过以下的提示来实现对学生的提交的作业的评分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 中文版\n",
    "prompt = \"\"\" 你的任务是判断学生的解决方案是正确的还是不正确的\n",
    "\n",
    "要解决该问题，请执行以下操作：\n",
    " - 首先，制定自己的问题解决方案\n",
    " - 然后将您的解决方案与学生的解决方案进行比较\n",
    " 并评估学生的解决方案是否正确。\n",
    "...\n",
    "使用下面的格式:\n",
    "\n",
    "问题:\n",
    "```\n",
    "问题文本\n",
    "```\n",
    "学生的解决方案:\n",
    "```\n",
    "学生的解决方案文本\n",
    "```\n",
    "实际解决方案:\n",
    "```\n",
    "...\n",
    "制定解决方案的步骤以及您的解决方案请参见此处\n",
    "```\n",
    "学生的解决方案和实际解决方案是否相同 \\\n",
    "只计算：\n",
    "```\n",
    "是或者不是\n",
    "```\n",
    "学生的成绩\n",
    "```\n",
    "正确或者不正确\n",
    "```\n",
    "\n",
    "问题:\n",
    "```\n",
    "{question}\n",
    "```\n",
    "学生的解决方案:\n",
    "```\n",
    "{student's solution}\n",
    "```\n",
    "实际解决方案:\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "此外，LangChain还提供了提示模版用于一些常用场景。比如自动摘要、问答、连接到SQL数据库、连接到不同的API. 通过使用LangChain内置的提示模版，你可以快速建立自己的大模型应用，而不需要花时间去设计和构造提示。\n",
    "\n",
    "最后，我们在建立大模型应用时，通常希望模型的输出为给定的格式，比如在输出使用特定的关键词来让输出结构化。 下面为一个使用大模型进行链式思考推理例子，对于问题：*What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?*\n",
    "\n",
    "通过使用LangChain库函数，输出采用\"Thought\"（思考）、\"Action\"（行动）、\"Observation\"（观察）作为链式思考推理的关键词，让输出结构化。\n",
    "\n",
    "```\n",
    "Thought: I need to search Colorado orogeny, find the area that the eastern sector of the Colorado orogeny extends into, then find the elevation range of the area.\n",
    "Action: Search[Colorado orogeny]\n",
    "Observation: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\n",
    "\n",
    "Thought: It does not mention the eastern sector. So I need to look up eastern sector.\n",
    "Action: Lookup[eastern sector]\n",
    "Observation: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\n",
    "\n",
    "Thought: The eastern sector of Colorado orogeny extends into the High Plains. So I need to search High Plains and find its elevation range.\n",
    "Action: Search[High Plains]\n",
    "Observation: High Plains refers to one of two distinct land regions\n",
    "\n",
    "Thought: I need to instead search High Plains (United States).\n",
    "Action: Search[High Plains (United States)]\n",
    "Observation: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation from around 1,800 to 7,000 ft (550 to 2,130 m).[3]\n",
    "\n",
    "Thought: High Plains rise in elevation from around 1,800 to 7,000 ft, so the answer is 1,800 to 7,000 ft.\n",
    "Action: Finish[1,800 to 7,000 ft]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "在补充材料中，可以查看使用LangChain和OpenAI进行链式思考推理的另一个代码实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3.3 输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "customer_review = \"\"\"\\\n",
    "这款吹叶机非常神奇。 它有四个设置：\\\n",
    "吹蜡烛、微风、风城、龙卷风。 \\\n",
    "两天后就到了，正好赶上我妻子的\\\n",
    "周年纪念礼物。 \\\n",
    "我想我的妻子会喜欢它到说不出话来。 \\\n",
    "到目前为止，我是唯一一个使用它的人，而且我一直\\\n",
    "每隔一天早上用它来清理草坪上的叶子。 \\\n",
    "它比其他吹叶机稍微贵一点，\\\n",
    "但我认为它的额外功能是值得的。\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.3.1 如果没有输出解析器\n",
    "\n",
    "对于给定的评价`customer_review`, 我们希望提取信息，并按以下格式输出：\n",
    "\n",
    "```python\n",
    "{\n",
    "  \"gift\": False,\n",
    "  \"delivery_days\": 5,\n",
    "  \"price_value\": \"pretty affordable!\"\n",
    "}\n",
    "```\n",
    "\n",
    "分析\n",
    "`response.content`类型为字符串（`str`），而并非字典(`dict`), 直接使用`get`方法会报错。因此，我们需要输出解释器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='对于以下文本，请从中提取以下信息：\\n\\n礼物：该商品是作为礼物送给别人的吗？ 如果是，则回答 是的；如果否或未知，则回答 不是。\\n\\n交货天数：产品需要多少天到达？ 如果没有找到该信息，则输出-1。\\n\\n价钱：提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表。\\n\\n使用以下键将输出格式化为 JSON：\\n礼物\\n交货天数\\n价钱\\n\\n文本: {text}\\n'))]\n",
      "{\n",
      "  \"礼物\": \"是的\",\n",
      "  \"交货天数\": 2,\n",
      "  \"价钱\": [\"它比其他吹叶机稍微贵一点\"]\n",
      "}\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 34\u001B[0m\n\u001B[1;32m     31\u001B[0m response \u001B[38;5;241m=\u001B[39m chat(messages)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28mprint\u001B[39m(response\u001B[38;5;241m.\u001B[39mcontent)\n\u001B[0;32m---> 34\u001B[0m \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m礼物\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "review_template = \"\"\"\\\n",
    "对于以下文本，请从中提取以下信息：\n",
    "\n",
    "礼物：该商品是作为礼物送给别人的吗？ \\\n",
    "如果是，则回答 是的；如果否或未知，则回答 不是。\n",
    "\n",
    "交货天数：产品需要多少天\\\n",
    "到达？ 如果没有找到该信息，则输出-1。\n",
    "\n",
    "价钱：提取有关价值或价格的任何句子，\\\n",
    "并将它们输出为逗号分隔的 Python 列表。\n",
    "\n",
    "使用以下键将输出格式化为 JSON：\n",
    "礼物\n",
    "交货天数\n",
    "价钱\n",
    "\n",
    "文本: {text}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(review_template)\n",
    "messages = prompt_template.format_messages(text=customer_review)\n",
    "print(prompt_template)\n",
    "\n",
    "api_key = os.environ.get(\"CHAT_ANYWHERE_API_KEY\")\n",
    "base_url = \"https://api.chatanywhere.com.cn/v1\"\n",
    "chat = ChatOpenAI(temperature=0.0, base_url=base_url, api_key=api_key)\n",
    "response = chat(messages)\n",
    "print(response.content)\n",
    "\n",
    "response.content.get(\"礼物\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### 3.3.2 LangChain输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "对于以下文本，请从中提取以下信息：：\n",
      "\n",
      "礼物：该商品是作为礼物送给别人的吗？\n",
      "如果是，则回答 是的；如果否或未知，则回答 不是。\n",
      "\n",
      "交货天数：产品到达需要多少天？ 如果没有找到该信息，则输出-1。\n",
      "\n",
      "价钱：提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表。\n",
      "\n",
      "文本: 这款吹叶机非常神奇。 它有四个设置：吹蜡烛、微风、风城、龙卷风。 两天后就到了，正好赶上我妻子的周年纪念礼物。 我想我的妻子会喜欢它到说不出话来。 到目前为止，我是唯一一个使用它的人，而且我一直每隔一天早上用它来清理草坪上的叶子。 它比其他吹叶机稍微贵一点，但我认为它的额外功能是值得的。\n",
      "\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"礼物\": string  // 这件物品是作为礼物送给别人的吗？如果是，则回答 是的；如果否或未知，则回答 不是。\n",
      "\t\"交货天数\": string  // 产品需要多少天才能到达？如果没有找到该信息，则输出-1。\n",
      "\t\"价钱\": string  // 提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表\n",
      "}\n",
      "```\n",
      "\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'礼物': '是的', '交货天数': '两天后', '价钱': '它比其他吹叶机稍微贵一点'}"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "\n",
    "# 中文\n",
    "review_template_2 = \"\"\"\\\n",
    "对于以下文本，请从中提取以下信息：：\n",
    "\n",
    "礼物：该商品是作为礼物送给别人的吗？\n",
    "如果是，则回答 是的；如果否或未知，则回答 不是。\n",
    "\n",
    "交货天数：产品到达需要多少天？ 如果没有找到该信息，则输出-1。\n",
    "\n",
    "价钱：提取有关价值或价格的任何句子，并将它们输出为逗号分隔的 Python 列表。\n",
    "\n",
    "文本: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "gift_schema = ResponseSchema(name=\"礼物\",\n",
    "                             description=\"这件物品是作为礼物送给别人的吗？\"\n",
    "                                         \"如果是，则回答 是的；如果否或未知，则回答 不是。\")\n",
    "delivery_days_schema = ResponseSchema(name=\"交货天数\",\n",
    "                                      description=\"产品需要多少天才能到达？如果没有找到该信息，则输出-1。\")\n",
    "price_value_schema = ResponseSchema(name=\"价钱\",\n",
    "                                    description=\"提取有关价值或价格的任何句子，\"\n",
    "                                                \"并将它们输出为逗号分隔的 Python 列表\")\n",
    "# 构造输出解析器\n",
    "response_schemas = [gift_schema, \n",
    "                    delivery_days_schema,\n",
    "                    price_value_schema]\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# print(format_instructions)\n",
    "\n",
    "# 构造LangChain提示模版\n",
    "prompt_template: ChatPromptTemplate = ChatPromptTemplate.from_template(review_template_2)\n",
    "messages: HumanMessage = prompt_template.format_messages(text=customer_review,\n",
    "                                                         format_instructions=format_instructions)\n",
    "print(messages[0].content)\n",
    "\n",
    "# 调用chat模型\n",
    "response: AIMessage = chat.__call__(messages)\n",
    "\n",
    "# 使用输出解析器解析输出\n",
    "output_dict = output_parser.parse(response.content)\n",
    "print(type(output_dict))\n",
    "output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 四、补充材料"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4.1 链式思考推理(ReAct)\n",
    "参考资料：[ReAct (Reason+Act) prompting in OpenAI GPT and LangChain](https://tsmatz.wordpress.com/2023/03/07/react-with-openai-gpt-and-langchain/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThought: I need to search David Chanoff and find the U.S. Navy admiral he collaborated with. Then I need to find the president under whom the admiral served as the ambassador to the United Kingdom.\n",
      "Action: Search[David Chanoff]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mDavid Chanoff is a noted author of non-fiction work. His work has typically involved collaborations with the principal protagonist of the work concerned. His collaborators have included; Augustus A. White, Joycelyn Elders, Đoàn Văn Toại, William J. Crowe, Ariel Sharon, Kenneth Good and Felix Zandman. He has also written about a wide range of subjects including literary history, education and foreign for The Washington Post, The New Republic and The New York Times Magazine. He has published more than twelve books.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mDavid Chanoff has collaborated with several individuals, including Augustus A. White, Joycelyn Elders, Đoàn Văn Toại, William J. Crowe, Ariel Sharon, Kenneth Good, and Felix Zandman. I need to search each of these individuals to find the U.S. Navy admiral. \n",
      "Action: Search[Augustus A. White]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mAugustus A. White III (born June 4, 1936) is the Ellen and Melvin Gordon Distinguished Professor of Medical Education and Professor of Orthopedic Surgery at Harvard Medical School and a former Orthopaedic Surgeon-in-Chief at Beth Israel Hospital, Boston, Massachusetts. White was the first African American medical student at Stanford, surgical resident at Yale University, professor of medicine at Yale, and department head at a Harvard-affiliated hospital (Beth Israel Hospital).\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mAugustus A. White III is not a U.S. Navy admiral. I need to search the next individual, Joycelyn Elders.\n",
      "Action: Search[Joycelyn Elders]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mMinnie Joycelyn Elders (born Minnie Lee Jones; August 13, 1933) is an American pediatrician and public health administrator who served as Surgeon General of the United States from 1993 to 1994. A vice admiral in the Public Health Service Commissioned Corps, she was the second woman, second person of color, and first African American to serve as Surgeon General. \n",
      "Elders is best known for her frank discussion of her views on controversial issues such as drug legalization, masturbation, and distributing contraception in schools. She was forced to resign in December 1994 amidst controversy as a result of her views. She is currently a professor emerita of pediatrics at the University of Arkansas for Medical Sciences.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mJoycelyn Elders is a pediatrician and public health administrator, not a U.S. Navy admiral. I need to search the next individual, Đoàn Văn Toại.\n",
      "Action: Search[Đoàn Văn Toại]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mĐoàn Văn Toại (1945 in Vietnam – November 2017 in California) was a Vietnamese-born naturalized American activist and the author of The Vietnamese Gulag (Simon & Schuster, 1986).\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mĐoàn Văn Toại is an activist and author, not a U.S. Navy admiral. I need to search the next individual, William J. Crowe.\n",
      "Action: Search[William J. Crowe]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mWilliam James Crowe Jr. (January 2, 1925 – October 18, 2007) was a United States Navy admiral and diplomat who served as the 11th chairman of the Joint Chiefs of Staff under Presidents Ronald Reagan and George H. W. Bush, and as the ambassador to the United Kingdom and Chair of the Intelligence Oversight Board under President Bill Clinton.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mWilliam J. Crowe is a U.S. Navy admiral and diplomat. I need to find the president under whom he served as the ambassador to the United Kingdom.\n",
      "Action: Search[William J. Crowe ambassador to United Kingdom]\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3mWilliam James Crowe Jr. (January 2, 1925 – October 18, 2007) was a United States Navy admiral and diplomat who served as the 11th chairman of the Joint Chiefs of Staff under Presidents Ronald Reagan and George H. W. Bush, and as the ambassador to the United Kingdom and Chair of the Intelligence Oversight Board under President Bill Clinton.\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mWilliam J. Crowe served as the ambassador to the United Kingdom under President Bill Clinton. So the answer is Bill Clinton.\n",
      "Action: Finish[Bill Clinton]\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bill Clinton'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.docstore.wikipedia import Wikipedia\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent, Tool, AgentExecutor\n",
    "from langchain.agents.react.base import DocstoreExplorer\n",
    "\n",
    "docstore = DocstoreExplorer(Wikipedia())\n",
    "tools = [\n",
    "  Tool(\n",
    "    name=\"Search\",\n",
    "    func=docstore.search,\n",
    "    description=\"Search for a term in the docstore.\",\n",
    "  ),\n",
    "  Tool(\n",
    "    name=\"Lookup\",\n",
    "    func=docstore.lookup,\n",
    "    description=\"Lookup a term in the docstore.\",\n",
    "  )\n",
    "]\n",
    "\n",
    "# 使用大语言模型\n",
    "llm = OpenAI(\n",
    "  model_name=\"gpt-3.5-turbo\",\n",
    "  temperature=0,\n",
    ")\n",
    "\n",
    "# 初始化ReAct代理\n",
    "react = initialize_agent(tools, llm, agent=\"react-docstore\", verbose=True)\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(\n",
    "  agent=react.agent,\n",
    "  tools=tools,\n",
    "  verbose=True,\n",
    ")\n",
    "\n",
    "\n",
    "question = \"Author David Chanoff has collaborated with a U.S. Navy admiral who served as the ambassador to the United Kingdom under which President?\"\n",
    "agent_executor.run(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}