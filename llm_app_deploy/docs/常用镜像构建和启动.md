## 常用AI基础镜像及启动命令

### 1、镜像Tag标识的含义
base/cuda: 包括 CUDA 运行时<br>
runtime: 在 base 的基础上，新增了 CUDA math 库和 NCCL、cuDNN 运行时<br>
devel: 在 runtime 的基础上，新增了头文件和用于构建 CUDA 镜像的开发工具，对于多阶段构建特别有用<br>
cuddn: 在上面基础上，新增了 cuDNN 神经网络加速库<br>
py3: Python 3 环境<br>

### 2、常用镜像

| 镜像名称                                          | 大小      | Python版本 | 备注                    |
|-----------------------------------------------|---------|----------|-----------------------|
| pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime | 2.94 GB | 3.10.9   | Tesla V100、CUDA 11.7  |
| pytorch/pytorch:2.1.2-cuda12.1-cudnn8-devel   | 8.25 GB |          | NVIDIA A100、CUDA 12.2 |
| pytorch/pytorch:2.1.2-cuda12.1-cudnn8-runtime | 3.24 GB |          | NVIDIA A100、CUDA 12.2 |
| nvidia/cuda:12.2.2-cudnn8-devel-ubuntu22.04   | 4.44 GB |          | NVIDIA A100、CUDA 12.2 |
| nvidia/cuda:12.2.2-cudnn8-runtime-ubuntu22.04 | 1.87 GB |          | NVIDIA A100、CUDA 12.2 |

> [PyTorch官方镜像](https://hub.docker.com/r/pytorch/pytorch/tags)<br>
> [Nvidia-Cuda官方镜像](https://hub.docker.com/r/nvidia/cuda/tags)

### 3、镜像构建与运行
+ 拉取镜像
```shell
# docker pull 一直有问题
docker pull pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime
docker pull pytorch/pytorch:2.4.0-cuda12.1-cudnn9-devel
```

+ 导入导出镜像
```shell
docker images
# docker save -o <保存路径>_<镜像文件>.tar <镜像名称>:<标签>
docker save -o pytorch_2.4.0-cuda12.1-cudnn9-runtime.tar pytorch/pytorch:2.4.0-cuda12.1-cudnn9-runtime
docker save -o pytorch_2.4.0-cuda12.1-cudnn9-devel.tar pytorch/pytorch:2.4.0-cuda12.1-cudnn9-devel

docker load -i pytorch_2.4.0-cuda12.1-cudnn9-runtime.tar
docker load -i pytorch_2.4.0-cuda12.1-cudnn9-devel.tar
```

+ 构建和启动镜像
```shell

# (1) 构建镜像
# 使用的镜像：FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime
docker build . -f Dockerfile -t harbor.qdyip.vip/algorithm-model/wzalgo_publicsentiment_extract:v3

# 操作镜像
docker images | grep wzalgo_publicsentiment_extract
docker rmi 08ba43b85201

# 验证镜像的环境是否正常
docker run --gpus all -it pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime /bin/bash
docker run --gpus all -it harbor.qdyip.vip/algorithm-model/wzalgo_recommender_nlp:2.0.0 /bin/bash
docker run --gpus all \
           -it --rm \
           pytorch/pytorch:2.2.2-cuda12.1-cudnn8-runtime bash

# 操作容器
docker ps -a | grep wzalgo_publicsentiment_extract
docker stop de98861baeac
docker start -p 3367:3367

docker rm de98861baeac
docker logs -f --tail=100 de98861baeac
docker exec -it 0b02b211721d /bin/bash 

>>> import torch
>>> torch.__version__

# (2) 通过挂载外部数据的方式读取模型文件和代码: 相当于在容器里运行的是/data/nfs/下的代码+模型，而不是原来的代码
-d: 后台运行
docker run --name wzalgo_recommender_nlp_v2 -p 3367:3367 --gpus all -v /data/nfs:/data/nfs -w /data/nfs/zcb/dev/wzalgo_recommender_nlp harbor.qdyip.vip/algorithm-model/wzalgo_recommender_nlp:2.0.0 /opt/conda/bin/gunicorn -c config/3367.config.py src.app4gpu:app
docker run -d --name wzalgo_recommender_nlp_v2 -p 3367:3367 --gpus all -v /data/nfs:/data/nfs -w /data/nfs/zcb/dev/wzalgo_recommender_nlp harbor.qdyip.vip/algorithm-model/wzalgo_recommender_nlp:2.0.0 /opt/conda/bin/gunicorn -c config/3367.config.py src.app4gpu:app

# (3) 推送到hub
docker push harbor.qdyip.vip/algorithm-model/wzalgo_recommender_nlp:2.0.0
```

### 参考引用
[1] [常用 AI 基础镜像及启动命令](https://www.chenshaowen.com/blog/common-ai-base-images-and-run-command.html)<br>
