
## 一、常用数据集格式
Alpaca 和 ShareGPT 是两种常见的数据格式，通常用于训练或微调基于指令（instruction-based）的语言模型。
每种格式都反映了数据组织和任务指令的不同方式。
 
### 1.1 Alpaca 格式
`Alpaca` 是基于 Meta 开源的 LLaMA 模型构建的一种微调数据集格式，特别用于 instruction-tuning，即`指令微调`。
其数据格式的特点是提供了一个明确的任务描述（instruction）、输入（input）和输出（output）三部分。
典型的 Alpaca 数据集格式：
```json
{
    "instruction": "Summarize the following text.",
    "input": "Artificial intelligence (AI) is a rapidly growing field...",
    "output": "AI is an evolving technology that is growing quickly in various fields..."
}
```

字段说明：
+ instruction: 任务的指令，告诉模型需要完成什么操作。
+ input: 任务所需的输入。如果任务是开放式的或者不需要明确的输入，这一字段可以为空字符串。 
+ output: 任务的期望输出，也就是模型在给定指令和输入情况下需要生成的内容。

特点：
+ 结构简单，易于理解。
+ 明确分离任务指令和输入内容，适合各种自然语言处理任务，如文本生成、翻译、总结等。

### 1.2 ShareGPT 格式
ShareGPT 格式来源于通过记录 ChatGPT 与用户对话的数据集，主要用于对话系统的训练。
它更侧重于多轮对话数据的收集和组织，模拟用户与 AI 之间的交互。
典型的 ShareGPT 数据集格式：
```json
{
    "conversations": [
        {
            "role": "user",
            "content": "What is the capital of France?"
        },
        {
            "role": "assistant",
            "content": "The capital of France is Paris."
        }
    ]
}
```
字段说明：
+ conversations: 这是一个对话列表，包含每轮对话的角色和内容。
+ role: 表示对话的角色，通常为“user”表示用户，“assistant”表示AI助手。
+ content: 具体的对话内容。

特点：
+ 结构适合对话场景，模型可以学习如何通过多轮互动来处理问题。
+ 更贴近人类与 AI 交互的方式，适用于构建和微调对话模型。

### 1.3 总结
| 格式       | 说明                                       |
|:---------|:-----------------------------------------|
| Alpaca   | 适用于指令驱动的任务，如文本生成、摘要、翻译等，具有清晰的指令、输入和输出字段。 |
| ShareGPT | 侧重于多轮对话，适用于对话系统的训练，模拟用户与 AI 的交互。         |


## 参考引用

[1] [大模型微调——训练数据集的格式Alpaca 和 ShareGPT](https://blog.csdn.net/qq_42755230/article/details/142880678) <br>
[2] [大模型微调数据集格式](https://www.zhihu.com/question/632804211) <br>
[3] [easy-dataset](https://docs.easy-dataset.com/) <br>
[4] [easy-dataset 博客](https://zhuanlan.zhihu.com/p/29942660863) <br>
[5] [easy-dataset GitHub](https://github.com/ConardLi/easy-dataset?tab=readme-ov-file) <br>
[6] [alpaca-zh 数据集示例](https://hf-mirror.com/datasets/shibing624/alpaca-zh/tree/main) <br>
