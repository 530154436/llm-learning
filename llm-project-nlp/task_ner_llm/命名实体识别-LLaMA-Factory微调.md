## ä¸€ã€ç¯å¢ƒé…ç½®
dockeré•œåƒ
```
FROM nvidia/cuda:12.2.2-cudnn8-runtime-ubuntu22.04
```
CUDAç‰ˆæœ¬
```shell
nvcc -V
# Cuda compilation tools, release 12.2, V12.2.140
# Build cuda_12.2.r12.2/compiler.33191640_0
```
LLaMa-Factoryç‰ˆæœ¬
```shell
llamafactory-cli version
#----------------------------------------------------------
#| Welcome to LLaMA Factory, version 0.9.2                |
#| Project page: https://github.com/hiyouga/LLaMA-Factory |
#----------------------------------------------------------
```
> å®˜æ–¹æ–‡æ¡£æ˜¯ git clone æ•´ä¸ªé¡¹ç›®ä»¥ä¾¿æ”¯æŒæœ€æ–°çš„æ¨¡å‹ã€‚

## äºŒã€å‡†å¤‡å·¥ä½œ
### 2.1 åŸºåº§æ¨¡å‹ä¸‹è½½
```python
from modelscope import snapshot_download
snapshot_download('Qwen/Qwen2.5-7B-Instruct', cache_dir='models', revision='master')
```
### 2.2 æ•°æ®é›†æ„å»ºï¼ˆalpacaæ ¼å¼ï¼‰
data/dataset/alpaca/dataset_info.json
```
{
  "alpaca_clue_train": {
    "file_name": "alpaca_clue_train.json"
  }
}
```
data/dataset/alpaca/alpaca_clue_train.json
```
[
  {
    "instruction": "ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬å®ä½“è¯†åˆ«é¢†åŸŸçš„ä¸“å®¶ï¼Œè¯·ä»ç»™å®šçš„å¥å­ä¸­è¯†åˆ«å¹¶æå–å‡ºä»¥ä¸‹æŒ‡å®šç±»åˆ«çš„å®ä½“ã€‚\n\n<å®ä½“ç±»åˆ«é›†åˆ>\nname, organization, scene, company, movie, book, government, position, address, game\n\n<ä»»åŠ¡è¯´æ˜>\n1. ä»…æå–å±äºä¸Šè¿°ç±»åˆ«çš„å®ä½“ï¼Œå¿½ç•¥å…¶ä»–ç±»å‹çš„å®ä½“ã€‚\n2. ä»¥jsonæ ¼å¼è¾“å‡ºï¼Œå¯¹äºæ¯ä¸ªè¯†åˆ«å‡ºçš„å®ä½“ï¼Œè¯·æä¾›ï¼š\n   - label: å®ä½“ç±»å‹ï¼Œå¿…é¡»ä¸¥æ ¼ä½¿ç”¨åŸå§‹ç±»å‹æ ‡è¯†ï¼ˆä¸å¯æ›´æ”¹ï¼‰\n   - text: å®ä½“åœ¨åŸæ–‡ä¸­çš„ä¸­æ–‡å†…å®¹\n\n<è¾“å‡ºæ ¼å¼è¦æ±‚>\n```json\n[{{\"label\": \"å®ä½“ç±»åˆ«\", \"text\": \"å®ä½“åç§°\"}}]\n```",
    "input": "æµ™å•†é“¶è¡Œä¼ä¸šä¿¡è´·éƒ¨å¶è€æ¡‚åšå£«åˆ™ä»å¦ä¸€ä¸ªè§’åº¦å¯¹äº”é“é—¨æ§›è¿›è¡Œäº†è§£è¯»ã€‚å¶è€æ¡‚è®¤ä¸ºï¼Œå¯¹ç›®å‰å›½å†…å•†ä¸šé“¶è¡Œè€Œè¨€ï¼Œ",
    "output": "[{\"label\": \"name\", \"text\": \"å¶è€æ¡‚\"}, {\"label\": \"company\", \"text\": \"æµ™å•†é“¶è¡Œ\"}]"
  }
]
```

## ä¸‰ã€å¼€å§‹è®­ç»ƒ
ä½¿ç”¨é…ç½®æ–‡ä»¶ï¼šconf/Qwen2.5-7B-Instruct-clue-ner-lora-sft.yaml
```
### model
model_name_or_path: ../model_hub/Qwen2.5-7B-Instruct
trust_remote_code: true

### method
stage: sft
do_train: true
finetuning_type: lora
flash_attn: auto
lora_rank: 8
lora_target: all

### dataset
dataset_dir: data/dataset/alpaca  # å­˜å‚¨æ•°æ®é›†çš„æ–‡ä»¶å¤¹è·¯å¾„ã€‚
dataset: alpaca_clue_train
template: qwen  # Qwen (1-2.5)
cutoff_len: 1024  # è¾“å…¥çš„æœ€å¤§ token æ•°ï¼Œè¶…è¿‡è¯¥é•¿åº¦ä¼šè¢«æˆªæ–­ã€‚
max_samples: 15000  # æ¯ä¸ªæ•°æ®é›†çš„æœ€å¤§æ ·æœ¬æ•°ï¼šè®¾ç½®åï¼Œæ¯ä¸ªæ•°æ®é›†çš„æ ·æœ¬æ•°å°†è¢«æˆªæ–­è‡³æŒ‡å®šçš„ max_samplesã€‚
overwrite_cache: true  # æ˜¯å¦è¦†ç›–ç¼“å­˜çš„è®­ç»ƒå’Œè¯„ä¼°æ•°æ®é›†ã€‚
preprocessing_num_workers: 16
dataloader_num_workers: 8

### output
output_dir: data/outputs/Qwen2.5-7B-Instruct-clue-ner-lora-sft
logging_steps: 10
save_steps: 500
plot_loss: true
overwrite_output_dir: true
save_only_model: false

### train
per_device_train_batch_size: 4  # æ¯è®¾å¤‡è®­ç»ƒæ‰¹æ¬¡å¤§å°
gradient_accumulation_steps: 8
learning_rate: 1.0e-4
num_train_epochs: 3.0
lr_scheduler_type: cosine
warmup_ratio: 0.1
bf16: true
ddp_timeout: 180000000
resume_from_checkpoint: null

### eval
#eval_dataset:
val_size: 0.1
per_device_eval_batch_size: 1
eval_strategy: steps
eval_steps: 500
```











### åŸºäºTransformers+peftæ¡†æ¶
åˆ©ç”¨å¤§æ¨¡å‹åšNERå®è·µ(æ€»ç»“ç‰ˆ)
https://mp.weixin.qq.com/s/LBlzFm8wxK7Aj7YXhCoXgQ
https://github.com/cjymz886/LLM-NER

LLM Finetuneï¼š
æŒ‡ä»¤å¾®è°ƒ-æ–‡æœ¬åˆ†ç±»
æŒ‡ä»¤å¾®è°ƒ-å‘½åå®ä½“è¯†åˆ«
åšå®¢ï¼šhttps://blog.csdn.net/SoulmateY/article/details/139831606
ä»£ç ï¼šhttps://github.com/Zeyi-Lin/LLM-Finetune

05-Qwen3-8B-LoRAåŠSwanLabå¯è§†åŒ–è®°å½•.md
https://github.com/datawhalechina/self-llm/blob/master/models/Qwen3/05-Qwen3-8B-LoRA%E5%8F%8ASwanLab%E5%8F%AF%E8%A7%86%E5%8C%96%E8%AE%B0%E5%BD%95.md

chinese_ner_sftæ•°æ®é›†
https://hf-mirror.com/datasets/qgyd2021/chinese_ner_sft


### LLaMA-Factory
å®˜ç½‘æ•™ç¨‹ï¼šhttps://llamafactory.readthedocs.io/zh-cn/latest/getting_started/sft.html
æ•°æ®é›†å‚æ•°ï¼šhttps://github.com/hiyouga/LLaMA-Factory/blob/main/src/llamafactory/hparams/data_args.py#L38
å‚æ•°é…ç½®ï¼šhttps://llamafactory.readthedocs.io/zh-cn/latest/advanced/arguments.html
æŸ¥çœ‹æç¤ºè¯æ¨¡æ¿ï¼šhttps://github.com/hiyouga/LLaMA-Factory/blob/main/README_zh.md

å¤§æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒæŠ€æœ¯åŸç†ç»¼è¿°ï¼ˆä¸€ï¼‰-èƒŒæ™¯ã€å‚æ•°é«˜æ•ˆå¾®è°ƒç®€ä»‹
https://github.com/liguodongiot/llm-action?tab=readme-ov-file
https://zhuanlan.zhihu.com/p/635152813

Qwen2.5å¤§æ¨¡å‹å¾®è°ƒå®æˆ˜ï¼šåŒ»ç–—å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡ï¼ˆå®Œæ•´ä»£ç ï¼‰
https://zhuanlan.zhihu.com/p/19682001982

åŸºäº Qwen2.5-0.5B å¾®è°ƒè®­ç»ƒ Ner å‘½åå®ä½“è¯†åˆ«ä»»åŠ¡
https://blog.csdn.net/qq_43692950/article/details/142631780

qwen3 finetune
https://qwen.readthedocs.io/zh-cn/latest/training/llama_factory.html


åœ¨è¿›è¡Œæ¨¡å‹å¾®è°ƒæ—¶ï¼Œæ˜¯å¦åº”è¯¥å°† system æ¶ˆæ¯ä¹ŸåŒ…å«åœ¨è®­ç»ƒæ•°æ®ä¸­ï¼Ÿ
ğŸ¯ æ§åˆ¶è§’è‰²ä¸€è‡´æ€§	åŒ…å« system å¯ä»¥å¸®åŠ©æ¨¡å‹æ›´ç¨³å®šåœ°è®°ä½è‡ªå·±çš„ä»»åŠ¡è§’è‰²ï¼ˆæ¯”å¦‚ï¼šå®ä½“è¯†åˆ«ä¸“å®¶ï¼‰ï¼Œé¿å…åœ¨ä¸åŒä»»åŠ¡ä¹‹é—´æ··æ·†ã€‚
ğŸ¤– æ›´è´´è¿‘å®é™…ä½¿ç”¨åœºæ™¯	å¦‚æœä½ åœ¨éƒ¨ç½²æˆ–æ¨ç†é˜¶æ®µä½¿ç”¨äº† system æ¥è®¾å®šè§’è‰²ï¼Œé‚£ä¹ˆåœ¨è®­ç»ƒæ—¶ä¹Ÿåº”è¯¥ä¿ç•™å®ƒï¼Œè¿™æ ·è®­ç»ƒå’Œæ¨ç†çš„ä¸Šä¸‹æ–‡æ‰ä¸€è‡´ã€‚
ğŸ§© æå‡æ³›åŒ–èƒ½åŠ›	æ¨¡å‹èƒ½æ›´å¥½åœ°ç†è§£â€œæˆ‘æ˜¯ä¸€ä¸ªå®ä½“è¯†åˆ«åŠ©æ‰‹â€ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªé€šç”¨é—®ç­”æ¨¡å‹ï¼Œä»è€Œåœ¨æ–°å¥å­ä¸Šè¡¨ç°æ›´å‡†ç¡®ã€‚
ğŸ§ª å¤šä»»åŠ¡è®­ç»ƒæ”¯æŒ	å¦‚æœä½ æœªæ¥è®¡åˆ’è®­ç»ƒå¤šä¸ªä»»åŠ¡ï¼ˆå¦‚å®ä½“è¯†åˆ« + å…³ç³»æŠ½å–ï¼‰ï¼Œå¯ä»¥é€šè¿‡ä¸åŒçš„ system æ¥åŒºåˆ†ä»»åŠ¡ç±»å‹ï¼Œæå‡æ¨¡å‹å¯æ§æ€§ã€‚
transformer gpt è¾“å…¥çš„maskå’Œbertçš„maskå¥½åƒæ˜¯ç›¸åçš„ï¼Ÿ
